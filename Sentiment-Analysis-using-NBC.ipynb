{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f78ba78a",
   "metadata": {},
   "source": [
    "###### Import the Data\n",
    "\n",
    "Our first step is going to be to import data. We have three dataset options to choose from in the kaggle link - IMDb, Amazon or Yelp. We are going to select IMDb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ea6282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "data= pd.read_csv('/content/imdb_labelled.txt', names=['Reviews','Sentiment'], delimiter = '\\t')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf1aaa6",
   "metadata": {},
   "source": [
    "This shows that we have 748 rows in our dataset.\n",
    "To view the data we can call the data object, which would print all the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2408f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fd1413",
   "metadata": {},
   "source": [
    "To make it unbiased, we would shuffle the data before splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c650c32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of the data\n",
    "shuffle_data = data.copy(deep=True)\n",
    "# shuffle data with sample().\n",
    "# frac = 1 is entire dataset, random_state=1 for reproducible data\n",
    "# and reset_index() to reset the index\n",
    "shuffle_data = shuffle_data.sample(frac=1, random_state=1).reset_index()\n",
    "shuffle_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33000d12",
   "metadata": {},
   "source": [
    " We can now proceed to split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4426a5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = shuffle_data[0:639]\n",
    "dev_data = shuffle_data[639:714]\n",
    "test_data = shuffle_data[714:]\n",
    "\n",
    "train_data.info()\n",
    "dev_data.info()\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a855666f",
   "metadata": {},
   "source": [
    "###### Making a word frequency list and dictionary\n",
    "\n",
    "We are going to make a list of all the words and a dictionary which would contain the frequency of the given word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7776ecce",
   "metadata": {},
   "source": [
    "To make our our job easier, we would remove all the special characters from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26790566",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =data.replace(to_replace = \"[^a-zA-Z0-9]\",value= \" \" ,regex=True)\n",
    "shuffle_data =shuffle_data.replace(to_replace = \"[^a-zA-Z0-9]\",value= \" \" ,regex=True)\n",
    "train_data =train_data.replace(to_replace = \"[^a-zA-Z0-9]\",value= \" \" ,regex=True)\n",
    "dev_data =dev_data.replace(to_replace = \"[^a-zA-Z0-9]\",value= \" \" ,regex=True)\n",
    "test_data =test_data.replace(to_replace = \"[^a-zA-Z0-9]\",value= \" \" ,regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a145f877",
   "metadata": {},
   "source": [
    "Then we move on to making the list and the dictionary by splitting the string and counting the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe3634b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list=[]\n",
    "words_freq={}\n",
    "word_list_pos=[]\n",
    "words_freq_pos={}\n",
    "word_list_neg=[]\n",
    "words_freq_neg={}\n",
    "\n",
    "for sentence,sentence_sentiment in zip(shuffle_data['Reviews'],shuffle_data['Sentiment']):\n",
    "  for word in sentence.split(' '):\n",
    "    word_lower = word.lower()\n",
    "\n",
    "    if word_lower not in word_list:\n",
    "      word_list.append(word_lower)\n",
    "      words_freq[word_lower] = 1\n",
    "\n",
    "      if sentence_sentiment == 1:\n",
    "        word_list_pos.append(word_lower)\n",
    "        words_freq_pos[word_lower] = 1\n",
    "      else:\n",
    "        word_list_neg.append(word_lower)\n",
    "        words_freq_neg[word_lower] = 1\n",
    "\n",
    "    else:\n",
    "      words_freq[word_lower] = words_freq[word_lower] + 1\n",
    "      \n",
    "      if sentence_sentiment == 1:\n",
    "        if word_lower not in word_list_pos:\n",
    "          word_list_pos.append(word_lower)\n",
    "          words_freq_pos[word_lower] = 1\n",
    "        else:\n",
    "          words_freq_pos[word_lower] = words_freq_pos[word_lower] + 1\n",
    "      else:\n",
    "        if word_lower not in word_list_neg:\n",
    "          word_list_neg.append(word_lower)\n",
    "          words_freq_neg[word_lower] = 1\n",
    "        else:\n",
    "          words_freq_neg[word_lower] = words_freq_neg[word_lower] + 1\n",
    "            \n",
    "print('word list:',word_list)\n",
    "print('word freq:',words_freq)\n",
    "\n",
    "print('word list pos:',word_list_pos)\n",
    "print('word freq pos:',words_freq_pos)\n",
    "\n",
    "print('word list neg:',word_list_neg)\n",
    "print('word freq neg:',words_freq_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04afd53f",
   "metadata": {},
   "source": [
    "We can improve the list by removing rare words, i.e. words with frequency < 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6cff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list=[]\n",
    "\n",
    "word_list=[k for k,v in words_freq.items() if v >= 5]\n",
    "word_list.sort()\n",
    "\n",
    "words_freq={k:v for k,v in words_freq.items() if v >= 5}\n",
    "\n",
    "word_list_pos=[item for item in word_list_pos if item in words_freq]\n",
    "word_list_pos.sort()\n",
    "words_freq_pos={k:v for k,v in words_freq_pos.items() if k in words_freq}\n",
    "\n",
    "word_list_neg=[item for item in word_list_pos if item in words_freq]\n",
    "word_list_neg.sort()\n",
    "words_freq_neg={k:v for k,v in words_freq_pos.items() if k in words_freq}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c649c9",
   "metadata": {},
   "source": [
    "###### Calculate the probability of the word \"the\"\n",
    "\n",
    "We have to calculate the probability of the word \"the\" as the part of our exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3872635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
