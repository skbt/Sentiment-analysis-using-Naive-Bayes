{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d59fa50",
   "metadata": {},
   "source": [
    "###### Import the Data\n",
    "\n",
    "Our first step is going to be to import data. We have three dataset options to choose from in the kaggle link - IMDb, Amazon or Yelp. We are going to select IMDb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5322dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "data= pd.read_csv('/content/imdb_labelled.txt', names=['Reviews','Sentiment'], delimiter = '\\t')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8428de",
   "metadata": {},
   "source": [
    "This shows that we have 748 rows in our dataset.\n",
    "To view the data we can call the data object, which would print all the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17ea26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3740d40",
   "metadata": {},
   "source": [
    "To make it unbiased, we would shuffle the data before splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d45644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of the data\n",
    "shuffle_data = data.copy(deep=True)\n",
    "# shuffle data with sample().\n",
    "# frac = 1 is entire dataset, random_state=1 for reproducible data\n",
    "# and reset_index() to reset the index\n",
    "shuffle_data = shuffle_data.sample(frac=1, random_state=1).reset_index()\n",
    "shuffle_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74065401",
   "metadata": {},
   "source": [
    " We can now proceed to split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3064d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = shuffle_data[0:639]\n",
    "dev_data = shuffle_data[639:714]\n",
    "test_data = shuffle_data[714:]\n",
    "\n",
    "train_data.info()\n",
    "dev_data.info()\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0df29e1",
   "metadata": {},
   "source": [
    "###### Making a word frequency list and dictionary\n",
    "\n",
    "We are going to make a list of all the words and a dictionary which would contain the frequency of the given word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cc51ef",
   "metadata": {},
   "source": [
    "To make our our job easier, we would remove all the special characters from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de992353",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =data.replace(to_replace = \"[^a-zA-Z0-9]\",value= \" \" ,regex=True)\n",
    "shuffle_data =shuffle_data.replace(to_replace = \"[^a-zA-Z0-9]\",value= \" \" ,regex=True)\n",
    "train_data =train_data.replace(to_replace = \"[^a-zA-Z0-9]\",value= \" \" ,regex=True)\n",
    "dev_data =dev_data.replace(to_replace = \"[^a-zA-Z0-9]\",value= \" \" ,regex=True)\n",
    "test_data =test_data.replace(to_replace = \"[^a-zA-Z0-9]\",value= \" \" ,regex=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
